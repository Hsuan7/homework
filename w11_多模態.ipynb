{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hsuan7/homework/blob/main/w11_%E5%A4%9A%E6%A8%A1%E6%85%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tLWw99YVpgZ",
        "outputId": "4573fb5a-ece0-4705-8640-1ef476c10c2b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Concatenate, Input, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "# 1. 載入並預處理股價數據\n",
        "stock_data = pd.read_csv('/content/drive/MyDrive/week11_ Multimodal/kaggle/DJIA_table(train).csv', index_col='Date', parse_dates=True)  # 讀取股價數據，並將日期作為索引\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))  # 初始化MinMaxScaler，將數據縮放到0到1之間\n",
        "scaled_stock_data = scaler.fit_transform(stock_data[['Close']])  # 對收盤價數據進行縮放處理"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRkFIEX5JfsC",
        "outputId": "07f90232-00b3-4169-f8ff-cf212f8ab48d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-24b65902d48f>:12: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  stock_data = pd.read_csv('/content/drive/MyDrive/week11_ Multimodal/kaggle/DJIA_table(train).csv', index_col='Date', parse_dates=True)  # 讀取股價數據，並將日期作為索引\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 2. 載入並預處理情緒數據\n",
        "sentiment_data = pd.read_csv('/content/drive/MyDrive/week11_ Multimodal/kaggle/RedditNews(train).csv', index_col='Date', parse_dates=True)  # 讀取新聞情緒數據，並將日期作為索引\n",
        "sentiment_data.fillna('', inplace=True)  # 將空值填充為空字符串\n",
        "\n",
        "# 將每日的所有新聞標題合併為一個字符串\n",
        "sentiment_data_grouped = sentiment_data.groupby(sentiment_data.index).agg({'News': ' '.join})  # 按日期合併新聞標題\n",
        "\n",
        "# 使用簡單的情緒評分（例如詞彙數量）作為情緒分析的占位符\n",
        "sentiment_data_grouped['Sentiment_Score'] = sentiment_data_grouped['News'].apply(lambda x: len(x.split()))  # 計算每行的單詞數作為情緒得分\n",
        "scaled_sentiment_data = scaler.fit_transform(sentiment_data_grouped[['Sentiment_Score']])  # 對情緒得分進行縮放處理\n",
        "\n"
      ],
      "metadata": {
        "id": "Y0JXvgPTJdI9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 準備訓練和測試數據集\n",
        "def create_dataset(data, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - look_back - 1):\n",
        "        X.append(data[i:(i + look_back), :])  # 將look_back個時間步的數據作為輸入\n",
        "        Y.append(data[i + look_back, 0])  # 將下一個時間步的目標值作為輸出\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 5  # 設定回溯時間步數\n",
        "\n",
        "# 股價數據集\n",
        "X_stock, Y_stock = create_dataset(scaled_stock_data, look_back)  # 創建股價數據的輸入和輸出\n",
        "\n",
        "# 情緒數據集\n",
        "X_sentiment, Y_sentiment = create_dataset(scaled_sentiment_data, look_back)  # 創建情緒數據的輸入和輸出\n",
        "\n",
        "# 確保兩個數據集具有相同的長度\n",
        "min_length = min(len(X_stock), len(X_sentiment))\n",
        "X_stock, Y_stock = X_stock[:min_length], Y_stock[:min_length]\n",
        "X_sentiment, Y_sentiment = X_sentiment[:min_length], Y_sentiment[:min_length]\n",
        "\n",
        "# 將數據分為訓練和測試數據\n",
        "X_stock_train, X_stock_test, Y_train, Y_test = train_test_split(X_stock, Y_stock, test_size=0.2, random_state=42)  # 分割股價數據集\n",
        "X_sentiment_train, X_sentiment_test, _, _ = train_test_split(X_sentiment, Y_sentiment, test_size=0.2, random_state=42)  # 分割情緒數據集"
      ],
      "metadata": {
        "id": "uFNsskFRILxV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 定義股價的LSTM模型\n",
        "input_stock = Input(shape=(look_back, X_stock.shape[2]))  # 定義股價數據的輸入層\n",
        "stock_lstm = LSTM(50, return_sequences=False)(input_stock)  # 添加LSTM層\n",
        "stock_dense = Dense(50, activation='relu')(stock_lstm)  # 添加全連接層\n",
        "\n",
        "# 5. 定義情緒數據的LSTM模型\n",
        "input_sentiment = Input(shape=(look_back, X_sentiment.shape[2]))  # 定義情緒數據的輸入層\n",
        "sentiment_lstm = LSTM(50, return_sequences=False)(input_sentiment)  # 添加LSTM層\n",
        "sentiment_dense = Dense(50, activation='relu')(sentiment_lstm)  # 添加全連接層"
      ],
      "metadata": {
        "id": "KvMc3xxHILu7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 合併兩個模型的輸出\n",
        "merged = Concatenate()([stock_dense, sentiment_dense])  # 將股價和情緒模型的輸出合併\n",
        "merged_dense = Dense(50, activation='relu')(merged)  # 添加全連接層\n",
        "dropout = Dropout(0.2)(merged_dense)  # 添加Dropout層防止過擬合\n",
        "output = Dense(1)(dropout)  # 添加輸出層"
      ],
      "metadata": {
        "id": "2vB7EygXILsL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 7. 編譯並訓練模型\n",
        "model = Model(inputs=[input_stock, input_sentiment], outputs=output)  # 定義模型\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')  # 編譯模型，使用均方誤差作為損失函數\n",
        "model.fit([X_stock_train, X_sentiment_train], Y_train, epochs=20, batch_size=32, validation_data=([X_stock_test, X_sentiment_test], Y_test))  # 訓練模型\n",
        "\n",
        "# 8. 進行預測\n",
        "y_pred = model.predict([X_stock_test, X_sentiment_test])  # 使用測試數據進行預測\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ahzcfn78ILkG",
        "outputId": "e6403b28-9a54-4568-88eb-65046782d5d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 0.0020 - val_loss: 2.6372e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 3.4070e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 3.2230e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 4.5667e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 5.8836e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 2.9636e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 2.8383e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 5.4703e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 6.4674e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 2.3758e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 5.7189e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 3.2651e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 5.0711e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 2.2898e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 2.8977e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 2.3970e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 2.0800e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 3.1081e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 2.0948e-04\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. 評估模型\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(Y_test, y_pred)  # 計算均方誤差\n",
        "r2 = r2_score(Y_test, y_pred)  # 計算R^2分數作為模型的準確率\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R^2 Score (Accuracy): {r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERLxC5g8JdCK",
        "outputId": "54715fc7-955d-4cec-bc6c-17bbf987eaf9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.00020947629628074557\n",
            "R^2 Score (Accuracy): 0.9970755825334396\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}